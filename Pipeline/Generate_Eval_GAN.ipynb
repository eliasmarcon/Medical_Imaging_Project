{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-o00I0hq-wxa"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from keras import Input\n",
        "from keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'D:/Medical_Imaging/Medical_Imaging_Zusatz/BreaKHis_v1/Dataset_40X/benign/adenosis/'\n",
        "\n",
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "\n",
        "images = []\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert('L')) #'LA', 'L'\n",
        "\n",
        "for image in os.listdir(path):\n",
        "\n",
        "    img = read(path + \"/\" + image)\n",
        "    # img = cv2.imread(path + folder + \"/\" + image)\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (HEIGHT, WIDTH))\n",
        "\n",
        "    # täusche RGB Image an damit das fürs ResNet als input verwendet werden kann\n",
        "    img = np.repeat(img[..., np.newaxis], 3, -1)\n",
        "\n",
        "    images.append(np.array(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(114, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "#Image shape\n",
        "images = np.array(images) / 255\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "LATENT_DIM = 32\n",
        "CHANNELS = 3\n",
        "\n",
        "def create_generator():\n",
        "    \n",
        "    gen_input = Input(shape=(LATENT_DIM, ))\n",
        "\n",
        "    x = Dense(128 * 16 * 16)(gen_input)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Reshape((16, 16, 128))(x)\n",
        "\n",
        "    x = Conv2D(256, 5, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2D(512, 5, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Conv2D(512, 5, padding='same')(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "    generator = Model(gen_input, x)\n",
        "    return generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_discriminator():\n",
        "    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n",
        "\n",
        "    x = Conv2D(256, 3)(disc_input)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2D(256, 4, strides=2)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2D(256, 4, strides=2)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2D(256, 4, strides=2)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Conv2D(256, 4, strides=2)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    discriminator = Model(disc_input, x)\n",
        "\n",
        "    optimizer = RMSprop(\n",
        "        lr=.0001,\n",
        "        clipvalue=1.0,\n",
        "        decay=1e-8\n",
        "    )\n",
        "\n",
        "    discriminator.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy'\n",
        "    )\n",
        "\n",
        "    return discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = create_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer count mismatch when loading weights from file. Model expected 8 layers, found 2 saved layers.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39916/269467918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Medical_Imaging/Medical_Imaging_Zusatz/Saved_Checkpoints/gan2_40x_49999.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;34m\"Layer count mismatch when loading weights from file. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;34mf\"Model expected {len(filtered_layers)} layers, found \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 8 layers, found 2 saved layers."
          ]
        }
      ],
      "source": [
        "generator.load_weights('D:/Medical_Imaging/Medical_Imaging_Zusatz/Saved_Checkpoints/gan2_40x_49999.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "discriminator.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "gan_input = Input(shape=(LATENT_DIM, ))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = Model(gan_input, gan_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = RMSprop(lr = .0001, clipvalue = 1.0, decay = 1e-8)\n",
        "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "# gan.build(input_shape=(LATENT_DIM, ))\n",
        "# \n",
        "model = gan.load_weights('D:/Medical_Imaging/Medical_Imaging_Zusatz/Saved_Checkpoints/gan2_40x_49999.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "iters = 15\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'summary'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39916/3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'summary'"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'predict'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39916/3189875352.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlatent_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLATENT_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
          ]
        }
      ],
      "source": [
        "latent_vectors = np.random.normal(size = (batch_size, LATENT_DIM))\n",
        "model.predict(latent_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backlog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global Variables\n",
        "NOISE_DIM = 100\n",
        "NUM_EXAMPLES_TO_GENERATE = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create generator class\n",
        "class Generator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(8 * 8 * 256, use_bias=False)\n",
        "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2DTranspose(256 * 8, (4, 4), strides=(1, 1), padding='same', use_bias=False)\n",
        "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv2DTranspose(256 * 4, (4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.batchnorm3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv2DTranspose(256 * 2, (4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.batchnorm4 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv2DTranspose(256 * 1, (4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.batchnorm5 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv5 = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.batchnorm6 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv6 = tf.keras.layers.Conv2DTranspose(1, (4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "    def call(self, x, training=True):\n",
        "        x = self.fc1(x)\n",
        "        x = self.batchnorm1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = tf.reshape(x, shape=(-1, 8, 8, 256))\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm3(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm4(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm5(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm6(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = tf.nn.tanh(self.conv6(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benign Types"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adenosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_adenosis = Generator()\n",
        "generator_optimizer_adenosis = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_adenosis = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/benign/adenosis/'\n",
        "save_dir_adenosis = \"D:/Medical_Imaging_Zusatz/Gan_Images/benign/adenosis/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_adenosis = tf.train.Checkpoint(generator_optimizer = generator_optimizer_adenosis, generator = generator_adenosis)\n",
        "checkpoint_adenosis.restore(tf.train.latest_checkpoint(checkpoint_path_adenosis))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_adenosis(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_adenosis, 'gan_image_{}_{:04d}.png'.format('adenosis', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fibroadenoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_fibroadenoma = Generator()\n",
        "generator_optimizer_fibroadenoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_fibroadenoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/benign/fibroadenoma/'\n",
        "save_dir_fibroadenoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/benign/fibroadenoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_fibroadenoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_fibroadenoma, generator = generator_fibroadenoma)\n",
        "checkpoint_fibroadenoma.restore(tf.train.latest_checkpoint(checkpoint_path_fibroadenoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_fibroadenoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_fibroadenoma, 'gan_image_{}_{:04d}.png'.format('fibroadenoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phyllodes_tumor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_phyllodes_tumor = Generator()\n",
        "generator_optimizer_phyllodes_tumor = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_phyllodes_tumor = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/benign/phyllodes_tumor/'\n",
        "save_dir_phyllodes_tumor = \"D:/Medical_Imaging_Zusatz/Gan_Images/benign/phyllodes_tumor/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_phyllodes_tumor = tf.train.Checkpoint(generator_optimizer = generator_optimizer_phyllodes_tumor, generator = generator_phyllodes_tumor)\n",
        "checkpoint_phyllodes_tumor.restore(tf.train.latest_checkpoint(checkpoint_path_phyllodes_tumor))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_phyllodes_tumor(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_phyllodes_tumor, 'gan_image_{}_{:04d}.png'.format('phyllodes_tumor', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tubular_adenoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_tubular_adenoma = Generator()\n",
        "generator_optimizer_tubular_adenoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_tubular_adenoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/benign/tubular_adenoma/'\n",
        "save_dir_tubular_adenoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/benign/tubular_adenoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_tubular_adenoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_tubular_adenoma, generator = generator_tubular_adenoma)\n",
        "checkpoint_tubular_adenoma.restore(tf.train.latest_checkpoint(checkpoint_path_tubular_adenoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_tubular_adenoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_tubular_adenoma, 'gan_image_{}_{:04d}.png'.format('tubular_adenoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut5Ayc5D-wxh"
      },
      "source": [
        "## Malignant Images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ductal_carcinoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_ductal_carcinoma = Generator()\n",
        "generator_optimizer_ductal_carcinoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_ductal_carcinoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/malignant/ductal_carcinoma/'\n",
        "save_dir_ductal_carcinoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/malignant/ductal_carcinoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_ductal_carcinoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_ductal_carcinoma, generator = generator_ductal_carcinoma)\n",
        "checkpoint_ductal_carcinoma.restore(tf.train.latest_checkpoint(checkpoint_path_ductal_carcinoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_ductal_carcinoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_ductal_carcinoma, 'gan_image_{}_{:04d}.png'.format('ductal_carcinoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lobular_carcinoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_lobular_carcinoma = Generator()\n",
        "generator_optimizer_lobular_carcinoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_lobular_carcinoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/malignant/lobular_carcinoma/'\n",
        "save_dir_lobular_carcinoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/malignant/lobular_carcinoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_lobular_carcinoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_lobular_carcinoma, generator = generator_lobular_carcinoma)\n",
        "checkpoint_lobular_carcinoma.restore(tf.train.latest_checkpoint(checkpoint_path_lobular_carcinoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_lobular_carcinoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_lobular_carcinoma, 'gan_image_{}_{:04d}.png'.format('lobular_carcinoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mucinous_carcinoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_mucinous_carcinoma = Generator()\n",
        "generator_optimizer_mucinous_carcinoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_mucinous_carcinoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/malignant/mucinous_carcinoma/'\n",
        "save_dir_mucinous_carcinoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/malignant/mucinous_carcinoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_mucinous_carcinoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_mucinous_carcinoma, generator = generator_mucinous_carcinoma)\n",
        "checkpoint_mucinous_carcinoma.restore(tf.train.latest_checkpoint(checkpoint_path_mucinous_carcinoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_mucinous_carcinoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_mucinous_carcinoma, 'gan_image_{}_{:04d}.png'.format('mucinous_carcinoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Papillary_carcinoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_papillary_carcinoma = Generator()\n",
        "generator_optimizer_papillary_carcinoma = tf.keras.optimizers.legacy.Adam(1e-4)\n",
        "\n",
        "checkpoint_path_papillary_carcinoma = 'D:/Medical_Imaging_Zusatz/Saved_Checkpoints/malignant/papillary_carcinoma/'\n",
        "save_dir_papillary_carcinoma = \"D:/Medical_Imaging_Zusatz/Gan_Images/malignant/papillary_carcinoma/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_papillary_carcinoma = tf.train.Checkpoint(generator_optimizer = generator_optimizer_papillary_carcinoma, generator = generator_papillary_carcinoma)\n",
        "checkpoint_papillary_carcinoma.restore(tf.train.latest_checkpoint(checkpoint_path_papillary_carcinoma))\n",
        "\n",
        "# random vector for image generation \n",
        "random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "predictions = generator_papillary_carcinoma(random_vector_for_generation, training = False)\n",
        "\n",
        "for number, prediction in enumerate(predictions):\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir_papillary_carcinoma, 'gan_image_{}_{:04d}.png'.format('papillary_carcinoma', number)))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P10W6iU--wxi"
      },
      "source": [
        "## Evaluate generated Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQCPLz2q-wxi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTfu_pgF-wxi"
      },
      "source": [
        "## Backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51_0JAOB-wxi"
      },
      "outputs": [],
      "source": [
        "# for index, checkpoint_path in enumerate(checkpoint_path_benign_array):\n",
        "\n",
        "#     # print(checkpoint_path)\n",
        "\n",
        "#     checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer, generator = generator)\n",
        "\n",
        "#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "#     # print(checkpoint)\n",
        "\n",
        "#     # random vector for image generation \n",
        "#     random_vector_for_generation = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "#     # print(random_vector_for_generation)\n",
        "\n",
        "#     predictions = generator(random_vector_for_generation, training = False)\n",
        "\n",
        "#     for number, prediction in enumerate(predictions):\n",
        "\n",
        "#         fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "#         #    for i in range(predictions.shape[0]):\n",
        "#         #       plt.subplot(4, 4, i + 1)\n",
        "#         plt.imshow(prediction[ :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "#         # plt.title(f'Generated image at epoch: {Temp}')\n",
        "#         plt.axis('off')\n",
        "#         # plt.close()\n",
        "#         plt.savefig(os.path.join(save_dir_benign_array[index], 'GAN_Image_{}_{:04d}.png'.format(benign_types[index], number)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMDb7unI-wxd"
      },
      "source": [
        "## Temp Checkpoint until each cancer type gets checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnA32qUD-wxe"
      },
      "outputs": [],
      "source": [
        "# temp_checkpoint_path = \"D:/Medical_Imaging_Zusatz/Saved_Checkpoints/checkpoints/\"\n",
        "\n",
        "# temp_checkpoint_array = [temp_checkpoint_path, temp_checkpoint_path, temp_checkpoint_path, temp_checkpoint_path]\n",
        "# temp_checkpoint_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kci3O-4-wxe",
        "outputId": "e3d19501-a9c9-4cdb-86e1-f9f38e1ff962"
      },
      "outputs": [],
      "source": [
        "# types_benign = utils.get_types_array(\"benign\")\n",
        "\n",
        "# print(types_benign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjL5G-Ga-wxf",
        "outputId": "f376f53f-5f5c-4252-ddab-56fa00eae01e"
      },
      "outputs": [],
      "source": [
        "# checkpoint_path_benign = 'D:/Saved_Checkpoints/benign/'\n",
        "# checkpoint_path_benign_array = utils.get_paths(checkpoint_path_benign, types_benign)\n",
        "\n",
        "# print(checkpoint_path_benign_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIOOzo0T-wxg",
        "outputId": "15845b69-0cc4-44aa-ba58-757139ab7c7d"
      },
      "outputs": [],
      "source": [
        "# #benign folders\n",
        "# save_dir_benign = \"D:/Medical_Imaging_Zusatz/Gan_Images/benign/\"\n",
        "# save_dir_benign_array = utils.get_paths(save_dir_benign, types_benign)\n",
        "\n",
        "# print(save_dir_benign_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generator = utils.Generator()\n",
        "# generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# utils.generate_sample_images(generator, generator_optimizer, checkpoint_path_benign_array[1], save_dir_benign_array[1], types_benign[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3fc63de107a3995f66d33859f380f73bd26ac40da4b187ce627a4472b1acbfe0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
